# -*- coding: utf-8 -*-
"""SummerCamp_Proje1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11UZChE_rzA37tturYaDepqySA24hGmet
"""

#1. Google Colaboratory Dosyası Açılması
"Insurance Dataset": https://www.kaggle.com/datasets/mirichoi0218/insurance



# Gerekli Kütüphanelerin Eklenmesi
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn.model_selection
import sklearn.linear_model
import sklearn.metrics
import sklearn.preprocessing

#3. Keşifsel Veri Analizi Yapılması

df = pd.read_csv("insurance.csv")
dataset=df

df.head()

df.tail()

df.shape

df.info()

df.describe().T

#Bmi(Vücut Kitle İndeksi)’nin dağılımını inceleyiniz
num_bins = 50
n, bins, patches = plt.hist(dataset.bmi, color='b',  histtype = 'bar', ec = 'black')
plt.ylabel ('Frequency')
plt.xlabel ('BMI')
plt.xlim([0, 80])  
  
plt.title ('Histogram BMI')
plt.show()

#normal dağılım olduğunu görüyoruz

#“smoker” ile “charges” arasındaki ilişkiyi inceleyiniz
df.groupby("smoker").agg({"charges":["count","sum","mean","median"]})

# ortalamanın sigara içenlerde daha yüksek olduğu görülmekte

#“smoker” (Sigara tüketen) ile “region”(Bölge) arasındaki ilişkiyi inceleyiniz.
df.groupby(["region","smoker"]).agg({"smoker":"count"})

#bölgelerin yaklaşık sigara içen ve içmeyen oranlarının eşit olduğunu söyleyebiliriz,
# ama yine de southeast bölgesinde sigara içen oranı daha yüksek diyebiliriz

#“bmi” ile “sex”(Cinsiyet) arasındaki ilişkiyi inceleyiniz.
df.groupby("sex").agg({"bmi":["count","mean","median","min","max"]})

#yaklaşık olarak ortalama değerler aynı fakat erkeklerde maximum bmi değerinin daha yüksek olduğunu söyleyebiliriz.

#En çok “children”’a sahip “region”’ı bulunuz.
df.groupby("region").agg({"children":"sum"}).reset_index().sort_values("children",ascending=False)

#yaklaşık olarak değerler aynı ancak southeast bölgesi en çok çocuk sayısına sahip

#“bmi” ile “children” arasındaki ilişkiyi inceleyiniz.
plt.scatter(x=df["children"], y=df["bmi"], color="red")
plt.xlabel("Children")
plt.ylabel("BMI")
plt.title("Children vs. BMI")
plt.show()

df.groupby("children").agg({"bmi":["count","mean","median","min","max"]})

# bmi ile çocuk sayısı arasında kuvvetli bir ilişki olduğu gözlenmemiştir.

#“bmi” değişkeninde outlier var mıdır? İnceleyiniz.
df["bmi"].describe().T
max_value = df["bmi"].mean() + 3*df["bmi"].std()
min_value = df["bmi"].mean() - 3*df["bmi"].std()
count = 0
list_index = []
for index, value in enumerate(df["bmi"]):
  if (value<min_value) | (value>max_value):
    count +=1
    list_index.append(index)
print(count)
df.loc[list_index]

# 4 tane outlier olduğu gözlemlenmiştir.

# “bmi” ile “charges” arasındaki ilişkiyi inceleyiniz.
plt.scatter(x=df["charges"], y=df["bmi"], color="green")
plt.xlabel("Charges")
plt.ylabel("BMI")
plt.title("Charges vs. BMI")
plt.show()

#charges değeri arttıkça bmi değerinde de bir artış gözlenmiştir ama kesin bir doğrusal oran vardır denilemez

#“region”, “smoker” ve “bmi” arasındaki ilişkiyi bar plot kullanarak inceleyiniz.

sns.barplot(x="region",y = "bmi",hue="smoker", data=df)

#bölgelere göre sigara içip içmeme oranının bmi üzerinde bir etkisi vardır denilemez

#4. Veri Ön İşleme Yapılması,
#Bu kısımda elinizde olan veriyi model eğitmek için hazır hale getiriniz.
#Kategorik değişkenleri düzenlemek için Label ve One-Hot Encoding tekniklerini kullanınız.
#Veri setinizi X_train,X_test, y_train, y_test olacak şekilde bölüştürünüz.
#Veri setini normalize ederek ölçekleyiniz.

#Bağımlı ve Bağımsız Değişkenleri Oluşturmak
X = dataset.drop("bmi",axis=1)
y = dataset["bmi"]

X.describe().T

X.info()

#onehot encoding
categoric = ["sex","smoker","region"]
one_hot_encoded_data = pd.get_dummies(X, columns = categoric,drop_first=True)
print(one_hot_encoded_data)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(one_hot_encoded_data)
y_scaled = y.values.reshape(-1, 1)

X_scaled

#train ve test gruplarının oluşturulması 
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_scaled, y_scaled, train_size=0.8)

#5. Model Seçme
#Birkaç regresyon modeli seçiniz bunları ön işleme yapılan veri ile eğitiniz
#Seçilen modellerin performanslarını çapraz doğrulama kullanarak inceleyiniz.
#En iyi performans gösteren modeli seçiniz

# Imports
from sklearn.linear_model import Lasso
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor

from sklearn import metrics

# Models Object
models = {
    'Lasso': {
        'model': Lasso()
    },
    'LinearRegression': {
        'model': LinearRegression()
    },
    'Ridge': {
        'model': Ridge()
    },
    'ElasticNet': {
        'model': ElasticNet()
    },
    'KNeighborsRegressor': {
        'model': KNeighborsRegressor()
    },
    'RandomForestRegressor': {
        'model': RandomForestRegressor()
    },
    'GradientBoostingRegressor': {
        'model': GradientBoostingRegressor()
    },
    'AdaBoostRegressor': {
        'model': AdaBoostRegressor(n_estimators = 5, learning_rate = 1.2, loss = 'exponential', random_state = 2)
    },
    'DecisionTreeRegressor': {
        'model': DecisionTreeRegressor(max_depth = 9, min_samples_split = 4, random_state = 1)
    }
}

# Add dictionary attributes
for model in models:
    models[model]['prediction'] = None
    models[model]['errors'] = {
        'mae': None,
        'mse': None,
        'rmse': None
    }
    models[model]['scores'] = {
        'r2': None
    }

# Let's try our luck with a bunch of models
for model in models:
    print('Running ', models[model]['model'])
    models[model]['model'].fit(X_train, y_train)
    models[model]['predictions'] = models[model]['model'].predict(X_test)
    models[model]['errors']['mae'] = metrics.mean_absolute_error(y_test, models[model]['predictions'])
    models[model]['errors']['mse'] = metrics.mean_squared_error(y_test, models[model]['predictions'])
    models[model]['errors']['rmse'] = np.sqrt(models[model]['errors']['mse'])
    models[model]['scores']['r2'] = metrics.r2_score(y_test, models[model]['predictions'])
    print('MAE: ', models[model]['errors']['mae'])
    print('MSE: ', models[model]['errors']['mse'])
    print('RMSE: ', models[model]['errors']['rmse'])
    print('R2: ', models[model]['scores']['r2'])
    print('\n')

#6. Hiper-parametre Optimizasyonu
#Bir önceki adımda seçilen modelin hiper-parametrelerinin optimize ediniz.
#Grid Search ile parametreleri optimize ediniz.

from sklearn.model_selection import GridSearchCV
GBR = GradientBoostingRegressor()
parameters = {'learning_rate': [0.01,0.02,0.03,0.04],
                  'subsample'    : [0.9, 0.5, 0.2, 0.1],
                  'n_estimators' : [100,500,1000, 1500],
                  'max_depth'    : [4,6,8,10]
                 }

grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)
grid_GBR.fit(X_train, y_train)

#7. Modeli Değerlendirme
print(" Results from Grid Search " )
print("\n The best estimator across ALL searched params:\n",grid_GBR.best_estimator_)
print("\n The best score across ALL searched params:\n",grid_GBR.best_score_)
print("\n The best parameters across ALL searched params:\n",grid_GBR.best_params_)